{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CTSE Assignment 02"
      ],
      "metadata": {
        "id": "dlsUfvAkecyC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## General Introduction"
      ],
      "metadata": {
        "id": "dhwecpS8fNb8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "**üë§ IT Number:** IT21304088\n",
        "**üìõ Name:** SHABEER M.S.M\n",
        "\n",
        "---\n",
        "\n",
        "### üìò Project Overview: CTSE Chatbot ü§ñ\n",
        "\n",
        "This project is a smart **AI-powered chatbot** designed to assist with answering questions based on **CTSE (Current Trends In Software Engineering)** lecture notes. It is implemented in a **Google Colab (Jupyter Notebook)** environment and follows a **Retrieval-Augmented Generation (RAG)** architecture.\n",
        "\n",
        "### üîß Key Features & Technologies:\n",
        "\n",
        "* üìÑ **PDF-Based QA**: Ingests lecture notes in PDF format for context-aware question answering.\n",
        "* üß† **RAG Pipeline**: Combines semantic search with generative AI to produce accurate, relevant responses.\n",
        "* üì¶ **Chroma Vector Store**: Stores semantic vectors of lecture note chunks for fast retrieval.\n",
        "* üåê **Google Gemini 2.0 Flash**: Leverages a cutting-edge generative model for response generation.\n",
        "* ‚ö° **Caching**: Speeds up repeat queries and reduces API calls.\n",
        "* üêû **Verbose Debugging Mode**: Enables detailed inspection with `--verbose`.\n",
        "* üìù **Markdown-Inspired Output**: Clean and readable formatting for better user experience."
      ],
      "metadata": {
        "id": "ZWtjWP7yer_s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PHASE 1: Dependency Installation"
      ],
      "metadata": {
        "id": "8CbVU2yjfU5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain langchain-community chromadb sentence-transformers pypdf langchain-google-genai gdown"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78Wxm6t1erjN",
        "outputId": "67186c69-714e-451f-86dd-1848a9c790dc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.24)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.23)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.11/dist-packages (1.0.8)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.11/dist-packages (5.4.0)\n",
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.55 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.56)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.39)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.4)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.9.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.2.2.post1)\n",
            "Requirement already satisfied: fastapi==0.115.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.115.9)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.2)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.0.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.13.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.21.1)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.32.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.32.1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.53b1)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.32.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.21.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.11/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (1.71.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.3.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.15.3)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (32.0.1)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from chromadb) (5.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.11/dist-packages (from chromadb) (3.10.18)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.11/dist-packages (from chromadb) (4.23.0)\n",
            "Requirement already satisfied: starlette<0.46.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi==0.115.9->chromadb) (0.45.3)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.51.3)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.30.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage<0.7.0,>=0.6.18 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (0.6.18)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (24.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.11/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.24.2)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.29.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=4.19.0->chromadb) (0.24.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (2.4.0)\n",
            "Requirement already satisfied: durationpy>=0.7 in /usr/local/lib/python3.11/dist-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.2.10)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
            "Requirement already satisfied: importlib-metadata<8.7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.6.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.32.1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.32.1)\n",
            "Requirement already satisfied: opentelemetry-proto==1.32.1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.32.1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.53b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.53b1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.53b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.53b1)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.53b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.53b1)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.53b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.53b1)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-asgi==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->chromadb) (2.19.1)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: httptools>=0.6.3 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.5)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.71.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.55->langchain) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.11/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PHASE 2: Importing Libraries"
      ],
      "metadata": {
        "id": "t2JNb7hffgYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "üì¶ Loads all essential libraries for:\n",
        "\n",
        "üìÅ File handling & Google Drive integration\n",
        "üìÑ PDF text extraction & document processing\n",
        "üß† Embeddings & vector database (Chroma) setup\n",
        "ü§ñ LLM configuration (Google Gemini 2.0 Flash)\n",
        "üîç Building a Retrieval-Augmented Generation (RAG) pipeline\n",
        "\n",
        "Everything you need to power the CTSE Chatbot! üöÄ\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import gdown\n",
        "from google.colab import drive\n",
        "from getpass import getpass\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.chains import create_retrieval_chain\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "import google.generativeai as genai"
      ],
      "metadata": {
        "id": "F9ZwGGKmemC6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PHASE 3: Environment Setup"
      ],
      "metadata": {
        "id": "zRHJhyo8fs7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "üöÄ Environment Setup & Initialization\n",
        "\n",
        "This block performs the following tasks:\n",
        "üìÇ 1. Mounts Google Drive to enable persistent file storage across sessions.\n",
        "üìÅ 2. Defines important file paths for accessing and saving project data.\n",
        "üì• 3. Downloads the CTSE lecture notes PDF for processing.\n",
        "üß† 4. Initializes an in-memory cache to store responses for repeated queries, improving performance.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "zCOvPySlf_Vm",
        "outputId": "5e184e67-a3fe-40ee-bf0a-143c6197fc6f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nüöÄ Environment Setup & Initialization\\n\\nThis block performs the following tasks:\\nüìÇ 1. Mounts Google Drive to enable persistent file storage across sessions.\\nüìÅ 2. Defines important file paths for accessing and saving project data.\\nüì• 3. Downloads the CTSE lecture notes PDF for processing.\\nüß† 4. Initializes an in-memory cache to store responses for repeated queries, improving performance.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive for persistent Chroma database storage\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7hkVfA9eXdM",
        "outputId": "7eddefc8-1f7f-4b35-93ed-18df89df7341"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define file paths and cache\n",
        "\n",
        "# Path for downloaded PDF\n",
        "DATA_PATH = \"/content/CTSE_Lecture_Notes.pdf\"\n",
        "# Path for Chroma vector database\n",
        "CHROMA_PATH = \"/content/drive/MyDrive/chroma_db_ctse_gemini\"\n",
        "# Dictionary to store cached query responses\n",
        "CACHE = {}"
      ],
      "metadata": {
        "id": "odbHblaUf3za"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download lecture notes PDF from Google Drive\n",
        "file_id = \"1fy4CWBFzfS1cxMxRlPiRIVdS0e4zihzQ\"\n",
        "gdown.download(f\"https://drive.google.com/uc?id={file_id}\", DATA_PATH, quiet=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "iuCXuxVrf03i",
        "outputId": "8df93c75-8907-4f17-cd9c-e9604bcf0483"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/CTSE_Lecture_Notes.pdf'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify PDF download\n",
        "if not os.path.exists(DATA_PATH):\n",
        "    print(f\"Error: Failed to download lecture notes to {DATA_PATH}\")\n",
        "else:\n",
        "    print(f\"Lecture notes downloaded to {DATA_PATH}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yp_tlc3ZeZiX",
        "outputId": "40dfd5be-d7d0-4725-ff5e-5aa789f12df2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lecture notes downloaded to /content/CTSE_Lecture_Notes.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up Google API key for Gemini\n",
        "print(\"Enter your Google API key for Gemini:\")\n",
        "api_key = getpass(\"API Key: \")\n",
        "os.environ[\"GOOGLE_API_KEY\"] = api_key\n",
        "genai.configure(api_key=api_key)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-d7p-VhuTKKH",
        "outputId": "b9f61bff-47e6-4870-bb96-9e57f10e6662"
      },
      "execution_count": 8,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Google API key for Gemini:\n",
            "API Key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PHASE 4: Load and Split Document"
      ],
      "metadata": {
        "id": "JdgppN25gGmZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "üìò PDF Loading & Chunking\n",
        "\n",
        "This section handles the following:\n",
        "üìÑ 1. Loads the CTSE lecture notes PDF into memory.\n",
        "‚úÇÔ∏è 2. Splits the document into manageable text chunks for processing.\n",
        "üìè 3. Uses a larger chunk size with overlap to retain contextual continuity.\n",
        "üéØ 4. Enhances the accuracy of information retrieval during query handling.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "RXUP0BiTgNBc",
        "outputId": "71651fea-9edd-493b-aef6-662eccb941da"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nüìò PDF Loading & Chunking\\n\\nThis section handles the following:\\nüìÑ 1. Loads the CTSE lecture notes PDF into memory.\\n‚úÇÔ∏è 2. Splits the document into manageable text chunks for processing.\\nüìè 3. Uses a larger chunk size with overlap to retain contextual continuity.\\nüéØ 4. Enhances the accuracy of information retrieval during query handling.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load PDF using PyPDFLoader\n",
        "print(\"Loading lecture notes...\")\n",
        "loader = PyPDFLoader(DATA_PATH)\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtwXcfbygOOP",
        "outputId": "e92aabb5-a3a8-4ece-a58f-ee717dfee06b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading lecture notes...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify document loading\n",
        "if not documents:\n",
        "    print(\"Error: No documents loaded from the PDF.\")\n",
        "else:\n",
        "    print(f\"Loaded {len(documents)} document pages.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZ5KHfmKgPEl",
        "outputId": "63d160e9-29ad-465e-8f26-8bccbaac0b93"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 408 document pages.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split documents into chunks for embedding\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,  # Larger chunk size to retain context\n",
        "    chunk_overlap=200  # Overlap to ensure continuity between chunks\n",
        ")\n",
        "docs = splitter.split_documents(documents)\n",
        "print(f\"Split into {len(docs)} chunks.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SNb8OAleZXg",
        "outputId": "43881d90-e4cd-47ec-9988-e167b5054bd8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split into 384 chunks.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PHASE 5: Embeddings and Vector Store Creation"
      ],
      "metadata": {
        "id": "GMrrjnWwgXnl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "üß† Embedding Generation & Vector Storage\n",
        "\n",
        "This block performs the following tasks:\n",
        "üîç 1. Generates text embeddings using Google's `embedding-001` model.\n",
        "üì¶ 2. Stores the embeddings in a Chroma vector database for efficient retrieval.\n",
        "üíæ 3. Persists the vector database to Google Drive to ensure data is retained across sessions.\n",
        "üß≤ 4. Configures a retriever to fetch relevant document chunks based on similarity search.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "EQqOAdkBgOHF",
        "outputId": "cdcf325e-20f1-4fea-9ae1-2e621694e93a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nüß† Embedding Generation & Vector Storage\\n\\nThis block performs the following tasks:\\nüîç 1. Generates text embeddings using Google's `embedding-001` model.\\nüì¶ 2. Stores the embeddings in a Chroma vector database for efficient retrieval.\\nüíæ 3. Persists the vector database to Google Drive to ensure data is retained across sessions.\\nüß≤ 4. Configures a retriever to fetch relevant document chunks based on similarity search.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize embedding model\n",
        "embedding_model_name = \"models/embedding-001\"\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=embedding_model_name)\n",
        "print(f\"Initialized embeddings: {embedding_model_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bC1gDNMAgdHn",
        "outputId": "b5d72729-4539-4cc6-f07d-aa9bcfd232dd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized embeddings: models/embedding-001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load or create Chroma vector store\n",
        "if os.path.exists(CHROMA_PATH):\n",
        "    print(f\"Loading vector store from {CHROMA_PATH}\")\n",
        "    vectorstore = Chroma(\n",
        "        persist_directory=CHROMA_PATH,\n",
        "        embedding_function=embeddings\n",
        "    )\n",
        "else:\n",
        "    print(f\"Creating vector store in {CHROMA_PATH}\")\n",
        "    vectorstore = Chroma.from_documents(\n",
        "        documents=docs,\n",
        "        embedding=embeddings,\n",
        "        persist_directory=CHROMA_PATH\n",
        "    )\n",
        "print(\"Vector store created.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qbXSqTmgdBm",
        "outputId": "0450d00c-9009-4590-82c2-e4826b1bfc10"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading vector store from /content/drive/MyDrive/chroma_db_ctse_gemini\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-15-6ad0ef6989a3>:4: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
            "  vectorstore = Chroma(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vector store created.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure retriever to fetch top 5 relevant chunks\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
        "print(\"Retriever configured.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saZVe5FGeZRy",
        "outputId": "f836e2e3-5653-4691-e1d4-3d38ffda093a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retriever configured.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PHASE 6: Language Model Initialization"
      ],
      "metadata": {
        "id": "8t2MiDNDgnYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "‚ú® Gemini Model Setup\n",
        "\n",
        "This step includes:\n",
        "ü§ñ 1. Initializes the `google/gemini-2.0-flash` model for fast and efficient response generation.\n",
        "‚öôÔ∏è 2. Prepares the model for integration with the retrieval pipeline.\n",
        "üöÄ 3. Enables high-performance question answering using retrieved context.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "8XO_lVeZguGk",
        "outputId": "177429ff-de14-4683-86fa-bfe8889915fe"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n‚ú® Gemini Model Setup\\n\\nThis step includes:\\nü§ñ 1. Initializes the `google/gemini-2.0-flash` model for fast and efficient response generation.\\n‚öôÔ∏è 2. Prepares the model for integration with the retrieval pipeline.\\nüöÄ 3. Enables high-performance question answering using retrieved context.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Gemini model\n",
        "model_id = \"gemini-2.0-flash\"\n",
        "print(f\"Initializing model: {model_id}\")\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=model_id,\n",
        "    temperature=0.7,\n",
        "    max_output_tokens=512,\n",
        "    top_p=0.95,\n",
        ")\n",
        "print(\"LLM initialized.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raNlZOoMgt1O",
        "outputId": "aca3c2a4-3972-4103-a641-361449279f04"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing model: gemini-2.0-flash\n",
            "LLM initialized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PHASE 7: RAG Chain Configurations"
      ],
      "metadata": {
        "id": "G2Wd2FZ-g6HJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "üõ†Ô∏è Sets up the Retrieval-Augmented Generation (RAG) pipeline:\n",
        "\n",
        "üßæ Uses a custom prompt to ensure answers stay grounded in the provided context\n",
        "üîç Connects the retriever (for relevant chunks) with the LLM (for smart responses)\n",
        "ü§ñ Enables context-aware, accurate answers based on lecture note content\n",
        "\n",
        "Making your chatbot both intelligent and trustworthy! ‚úÖ\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "qFAAFtang-cq",
        "outputId": "75b73a6b-198e-4f64-a130-0991355efb34"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nüõ†Ô∏è Sets up the Retrieval-Augmented Generation (RAG) pipeline:\\n\\nüßæ Uses a custom prompt to ensure answers stay grounded in the provided context  \\nüîç Connects the retriever (for relevant chunks) with the LLM (for smart responses)  \\nü§ñ Enables context-aware, accurate answers based on lecture note content\\n\\nMaking your chatbot both intelligent and trustworthy! ‚úÖ\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define custom prompt for RAG\n",
        "prompt = ChatPromptTemplate.from_template(\n",
        "    \"Context from Lecture Notes:\\n\"\n",
        "    \"{context}\\n\\n\"\n",
        "    \"Based on the above context, provide a concise answer (up to 3 sentences) to the following question.\\n\"\n",
        "    \"Summarize relevant information (e.g., bullet points, definitions) and answer ONLY the question asked.\\n\"\n",
        "    \"If the context does not contain the answer, respond with: \"\n",
        "    \"\\\"No answer For question based on the provided notes.\\\"\\n\\n\"\n",
        "    \"Question: {input}\"\n",
        ")"
      ],
      "metadata": {
        "id": "KfDUpGOLg-T7"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create document chain to process retrieved documents\n",
        "document_chain = create_stuff_documents_chain(llm, prompt)"
      ],
      "metadata": {
        "id": "CY5jiLP4hJhW"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create RAG chain combining retriever and document chain\n",
        "rag_chain = create_retrieval_chain(retriever, document_chain)\n",
        "print(\"RAG chain created. Ready to answer questions.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOKLlMM2eY7X",
        "outputId": "150bc9c5-4768-46e4-918a-da39fd2d7d19"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RAG chain created. Ready to answer questions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PHASE 8: Realtime Chat Loop"
      ],
      "metadata": {
        "id": "thAmrGrGhMjZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "üí¨ Implements an interactive chatbot loop:\n",
        "\n",
        "‚ö° Supports caching to speed up repeated queries\n",
        "üìù Enables verbose mode to show source documents for transparency\n",
        "üñãÔ∏è Uses Markdown-style formatting for clean, readable responses\n",
        "\n",
        "Ask questions and get smart, context-aware answers instantly! üöÄ\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "9us-I4sweY0H",
        "outputId": "1c06fe9a-acba-4170-b305-550644a0c210"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nüí¨ Implements an interactive chatbot loop:\\n\\n‚ö° Supports caching to speed up repeated queries  \\nüìù Enables verbose mode to show source documents for transparency  \\nüñãÔ∏è Uses Markdown-style formatting for clean, readable responses  \\n\\nAsk questions and get smart, context-aware answers instantly! üöÄ\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xc1cusYWePWY",
        "outputId": "cc09dabf-b7a8-4d6f-844a-1985724bec77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üöÄ========================================üöÄ\n",
            "         üìö Welcome to CTSE Bot ü§ñ         \n",
            "===========================================\n",
            "üí¨ Ask me anything about your lecture notes!\n",
            "üîç Add '--verbose' to view source details.\n",
            "‚ùå Type 'exit' anytime to leave the chat.\n",
            "\n",
            "‚ùì Question: what is docker?\n",
            "\n",
            "‚è≥ Processing...\n",
            "\n",
            "Question: what is docker?\n",
            "\n",
            "Answer:\n",
            "Docker is a container engine that packages and runs applications in loosely isolated environments. It provides tooling and a platform to manage the lifecycle of containers, allowing developers to develop, distribute, test, and deploy applications as containers. Docker as a concept can refer to a company, product, platform, CLI tool, or computer program.\n",
            "\n",
            "\n",
            "ü§ñ I'm ready! Ask your next question or type 'exit' to sign off.\n",
            "\n",
            "‚ùì Question: What is kubernetes?\n",
            "\n",
            "‚è≥ Processing...\n",
            "\n",
            "Question: What is kubernetes?\n",
            "\n",
            "Answer:\n",
            "Kubernetes (k8s) is an open-source platform for automating deployment, scaling, and management of containers at scale. It's a container orchestration platform originally created by Google and now managed by the CNCF. The current stable version is 1.32.\n",
            "\n",
            "\n",
            "ü§ñ I'm ready! Ask your next question or type 'exit' to sign off.\n",
            "\n",
            "‚ùì Question: Who is Shabeer?\n",
            "\n",
            "‚è≥ Processing...\n",
            "\n",
            "Question: Who is Shabeer?\n",
            "\n",
            "Answer:\n",
            "No answer For question based on the provided notes.\n",
            "\n",
            "\n",
            "ü§ñ I'm ready! Ask your next question or type 'exit' to sign off.\n",
            "\n",
            "‚ùì Question: exit\n",
            "\n",
            "ü§ñ Session ended. See you next time!\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Print chatbot introduction\n",
        "print(\"\\nüöÄ========================================üöÄ\")\n",
        "print(\"         üìö Welcome to CTSE Bot ü§ñ         \")\n",
        "print(\"===========================================\")\n",
        "print(\"üí¨ Ask me anything about your lecture notes!\")\n",
        "print(\"üîç Add '--verbose' to view source details.\")\n",
        "print(\"‚ùå Type 'exit' anytime to leave the chat.\\n\")\n",
        "\n",
        "# Main loop for user interaction\n",
        "while True:\n",
        "    query = input(\"‚ùì Question: \")\n",
        "\n",
        "    # Handle exit command\n",
        "    if query.strip().lower() == 'exit':\n",
        "        print(\"\\nü§ñ Session ended. See you next time!\\n\")\n",
        "        break\n",
        "\n",
        "    # Handle verbose mode and normalize query\n",
        "    verbose = False\n",
        "    if '--verbose' in query:\n",
        "        verbose = True\n",
        "        query = query.replace('--verbose', '').strip()\n",
        "\n",
        "    # Validate and normalize input\n",
        "    query = ' '.join(query.split())  # Remove extra spaces\n",
        "    if not query:\n",
        "        print(\"\\n‚ö†Ô∏è Error: Please enter a valid question.\")\n",
        "        continue\n",
        "\n",
        "    # Log processing\n",
        "    print(\"\\n‚è≥ Processing...\")\n",
        "\n",
        "    try:\n",
        "        # Check cache and validate response\n",
        "        if query in CACHE:\n",
        "            cached_answer = CACHE[query]['answer']\n",
        "            # Re-invoke if cached answer is the fallback response\n",
        "            if cached_answer == \"I cannot answer this question based on the provided notes.\":\n",
        "                result = rag_chain.invoke({\"input\": query})\n",
        "                CACHE[query] = {'answer': result['answer'], 'context': result['context']}\n",
        "            else:\n",
        "                print(f\"\\nQuestion: {query}\\n\")\n",
        "                print(\"Answer (Cached):\")\n",
        "                print(f\"{cached_answer}\\n\")\n",
        "                if verbose:\n",
        "                    print(\"üìö Source Documents (Cached):\")\n",
        "                    for i, doc in enumerate(CACHE[query]['context'], 1):\n",
        "                        print(f\"- Source {i} (Page: {doc.metadata.get('page', 'N/A')}):\")\n",
        "                        print(f\"{doc.page_content[:300]}{'...' if len(doc.page_content) > 300 else ''}\")\n",
        "                        print(\"\" + \"-\" * 100)\n",
        "                print(\"\\nü§ñ Need more help? Enter your next question or type 'exit' to sign off.\\n\")\n",
        "                continue\n",
        "\n",
        "        # Invoke RAG chain\n",
        "        result = rag_chain.invoke({\"input\": query})\n",
        "\n",
        "        # Cache response\n",
        "        CACHE[query] = {\n",
        "            'answer': result['answer'],\n",
        "            'context': result['context']\n",
        "        }\n",
        "\n",
        "        # Print refined terminal-friendly output\n",
        "        print(f\"\\nQuestion: {query}\\n\")\n",
        "        print(\"Answer:\")\n",
        "        print(f\"{result['answer']}\\n\")\n",
        "        if verbose:\n",
        "            print(\"üìö Source Documents:\\n\")\n",
        "            for i, doc in enumerate(result['context'], 1):\n",
        "                print(f\"- Source {i} (Page: {doc.metadata.get('page', 'N/A')}):\")\n",
        "                print(f\"{doc.page_content[:300]}{'...' if len(doc.page_content) > 300 else ''}\")\n",
        "                print(\"\" + \"-\" * 100)\n",
        "        print(\"\\nü§ñ I'm ready! Ask your next question or type 'exit' to sign off.\\n\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n Error: {e}\")\n",
        "        print(\"Please check your input, ensure the PDF is accessible\")"
      ]
    }
  ]
}